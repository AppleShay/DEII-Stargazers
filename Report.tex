\documentclass[12pt,a4paper]{article}


%----------------------------------------------------------------------
% PACKAGES AND BASIC SETUP
%----------------------------------------------------------------------
\usepackage[utf8]{inputenc}        % For UTF-8 encoding
\usepackage[T1]{fontenc}           % For proper accented characters
\usepackage{lmodern}               % Latin Modern font
\usepackage{geometry}              % Adjust page margins
\geometry{margin=1in}             % 1-inch margins all around
\usepackage[backend=bibtex]{biblatex}  
\addbibresource{sample.bib}  
\usepackage[margin=1in]{geometry}
\usepackage{amsmath}
\usepackage{url}
\usepackage{hyperref}
\usepackage{titlesec}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{caption}
\usepackage{setspace}              % For line spacing if needed
%\onehalfspacing                    % Uncomment for 1.5 spacing
\usepackage{multirow} % Add this to the preamble
\usepackage{caption}

\usepackage{graphicx}              % For including images
\usepackage{hyperref}              % Clickable links in PDF
\usepackage{amsmath,amssymb}       % Math symbols if needed
\usepackage{parskip}               % Blank line between paragraphs
\usepackage{float}
\usepackage{xcolor}
% If you want MLA or APA style references, you can use biblatex or natbib
% e.g.:
%----------------------------------------------------------------------
% TITLE PAGE INFO
%----------------------------------------------------------------------
\title{

    \rule{\textwidth}{4pt}\\[10pt]
    \huge \textbf{Data Engineering Project Report}
    \rule{\textwidth}{1pt}\\[15pt]
    
    \huge \color{darkgray}\textbf{StarGazers Predictor: GitHub Stars Prediction Pipeline}\\[15pt]
    
    \large \textbf{Department of Information Technology}\\[15pt]
    \large \textbf{By Group 2}\\[5pt]


}
\author{
    Shaheryar\\
    \texttt{shaheryar.4822@student.uu.se}
    \and
    Rick\\
    \texttt{@student.uu.se}
    \and
    Feruz\\
    \texttt{@student.uu.se}
    \and
    Lu\\
    \texttt{lu.chen.9450@student.uu.se}
    \and
    Linjia\\
    \texttt{@student.uu.se}
    }
\date{\today} % Updates Daily


\begin{document}

\maketitle

\section{Introduction}
In the open source community, the number of GitHub stars is often regarded as an important indicator of project popularity, similar to the number of subscriptions or likes on YouTube. With the surge in the number of open source projects, how to use existing data to accurately predict the number of stars a project may get in the future will not only help developers optimize project management strategies, but also have practical significance for studying the evolution of the open source ecosystem.

There is a certain correlation between the activity of a project (such as submission frequency, number of branches, number of contributors) and its popularity. Through machine learning methods such as linear regression, decision trees, random forests, etc., we can also model and predict the popularity of open source projects. To this end, this project proposes and implements a complete "StarGazers Predictor" system architecture. The system collects historical data of open source projects through the GitHub API, extracts key features, trains multiple prediction models, and selects the best model based on the prediction accuracy. We built a prediction model based on the activity of GitHub repositories, and deployed the system using two virtual machines, one for model development and training, and the other for production deployment, and used GitHooks to achieve continuous integration and delivery of the model. Finally, the deployed application can predict and rank 5 GitHub projects, simulating the actual application scenario of the recommendation system.

This study not only verified the differences in prediction accuracy among different models, but also evaluated the scalability and practicality of the overall system, providing technical support for open source project evaluation and intelligent recommendation.

\section{Related Work}
Early research treated GitHub stars as a direct indicator of repository popularity and explored simple predictive models. For example, Borges et al.\cite{3} applied multiple linear regression to forecast the number of stars a repository might receive. They found that incorporating recent project activity significantly improved accuracy, and their models performed best when trained on data from the last six months of activity. Features like commit frequency, number of forks, and number of watchers were shown to correlate strongly with popularity, suggesting that active development and user interest contribute to a repository's appeal.


Subsequent studies have explored this topic using more advanced methods and broader datasets. A study by Han et al. (2019) conducted a large-scale study of over 400,000 repositories to classify which projects would cross a popularity threshold of 100 stars. They collected 35 different features about each repository, including development activity such as open issues, number of branches, and contributor count. Using a random forest classifier, their model achieved strong results and identified development activity as a key predictor of success.\cite{1}  

Another relevant study was carried out by Sahin et al. (2019),\cite{4} who used recurrent neural networks to model GitHub popularity as a time-series prediction task. Their model incorporated key metrics like commits, forks, releases, and contributor information, with additional weighting based on user influence. The study demonstrated that development activity and user engagement features are valuable inputs for forecasting future popularity. Ren et al.\cite{2} proposed a model called StarIn, which combines traditional repository activity features with social influence metrics derived from the networks of stargazers and their followers. Their approach uses XGBoost to predict future star counts and showed strong performance compared to other baseline models. By incorporating both development activity and social dynamics, the study highlights the importance of considering how user interactions and influence affect repository popularity.

Building on this foundation, our project uses different methods like XGBoost and random forest and uses the best model to predict the number of stargazers a repository may receive. The features used include commonly available GitHub statistics like the number of commits, forks, and watchers. This model allows us to take into account subtle interactions between these features and aims to produce more accurate results than earlier approaches that relied on basic statistical models or a narrow set of variables.

\section{System Architecture}
Our system is structured as a modular pipeline:
\begin{itemize}
    \item \textbf{Data Collection:} GitHub API used to collect metadata for 1000 repositories with $>$50 stars.
    \item \textbf{Feature Engineering:} Extracted and computed features like \textit{commits, forks, watchers, project age, update delay, etc.}
    \item \textbf{Model Training:} Regression models trained using Scikit-learn pipelines with standard preprocessing.
    \item \textbf{Serving:} A FastAPI app exposes the best model via REST endpoint, or a flask application, deployed with Docker and CI/CD via GitHooks and Ansible on separate Dev/Prod VMs.
\end{itemize}

\section{Results}
\subsection{Scalability Analysis}
While our dataset is limited to 1000 repositories (due to GitHub API limits), our architecture supports horizontal scaling. Data collection can be parallelized, the FastAPI service is Dockerized for deployment via Kubernetes or Docker Swarm, and models are trained using scikit-learn pipelines compatible with distributed training if needed. The system is built with modularity and extensibility in mind, allowing future scale-up in both data and user requests.

\subsection{Model Comparison and Accuracy}
We evaluated five models:
\begin{itemize}[noitemsep]
    \item Linear Regression: R² = 0.54
    \item Ridge Regression: R² = 0.54
    \item Random Forest: R² = 0.50
    \item XGBoost: R² = 0.61
    \item LightGBM: R² = 0.59
\end{itemize}

The best performance was achieved using \textbf{XGBoost}, and it was exported as a `.pkl` artifact used in the deployed app. Predictions on real-world repositories showed close alignment with actual star counts, validating the generalization of the model.

\section{Conclusion}
We demonstrated an end-to-end predictive pipeline for estimating GitHub stars based on repository metadata. The system is modular, reproducible, and production-ready. Future extensions may include time-series forecasting or community activity trends to improve accuracy further.

\begin{thebibliography}{9}

\bibitem{1}
J. Han, S. Deng, X. Xia, D. Wang, and J. Yin,  
\textit{Characterization and prediction of popular projects on GitHub},  
In Proceedings of the 43rd IEEE Annual Computer Software and Applications Conference (COMPSAC), 2019, pp. 190--199.


\bibitem{2} L. Ren, S. Shan, X. Xu, and Y. Liu, \textit{StarIn: An Approach to Predict the Popularity of GitHub Repository}, Proc. 6th Int. Conf. of Pioneering Computer Scientists, Engineers and Educators (ICPCSEE 2020), 2020, pp. 258--273.

\bibitem{3}
H. Borges, A. Hora, and M. T. Valente,
\textit{Predicting the popularity of GitHub repositories},
In Proceedings of the 12th International Conference on Predictive Models and Data Analytics in Software Engineering, 2016, pp. 1--10.

\bibitem{4}
S. E. Sahin, K. Karpat, and A. Tosun,  
\textit{Predicting popularity of open source projects using recurrent neural networks},  
IEEE Access, vol. 7, pp. 149601--149615, 2019.

\end{thebibliography}



\end{document}
